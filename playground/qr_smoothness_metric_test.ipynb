{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dadrah.playground.qr_playground_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-378dbc1113ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdadrah\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_constants\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvande\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdadrah\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayground\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqr_playground_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplmo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdadrah\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayground\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayground_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpgut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdadrah\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manomaly_score_strategy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mansc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dadrah.playground.qr_playground_model'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.cm as cm\n",
    "from recordtype import recordtype\n",
    "from collections import defaultdict\n",
    "\n",
    "import dadrah.util.string_constants as stco\n",
    "import vande.vae.layers as layers\n",
    "import dadrah.playground.qr_playground_model as plmo\n",
    "import dadrah.playground.playground_util as pgut\n",
    "import dadrah.selection.anomaly_score_strategy as ansc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameters = recordtype('Parameters','vae_run_n, qcd_train_sample_id, qcd_test_sample_id, \\\n",
    "                        sig_sample_id, strategy_id, read_n, quantile')\n",
    "train_split = 0.3\n",
    "params = Parameters(\n",
    "                vae_run_n=113,\n",
    "                qcd_train_sample_id='qcdSigAllTrain'+str(int(train_split*100))+'pct', \n",
    "                qcd_test_sample_id='qcdSigAllTest'+str(int((1-train_split)*100))+'pct',\n",
    "                sig_sample_id='GtoWW35naReco',\n",
    "                strategy_id='rk5_05',\n",
    "                read_n=int(1e5),\n",
    "                quantile=0.9,\n",
    "                )\n",
    "\n",
    "qr_run_n_wiggly = 222\n",
    "qr_run_n_smooth = 223"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd_test_sample = pgut.read_sample(params.qcd_test_sample_id, params, 'qcd_sqrtshatTeV_13TeV_PU40_NEW_ALL_Test_signalregion_parts')\n",
    "\n",
    "#****************************************#\n",
    "#           prepare inputs & targets\n",
    "#****************************************#\n",
    "score_strategy = ansc.an_score_strategy_dict[params.strategy_id]\n",
    "x_test, y_test = qcd_test_sample['mJJ'], score_strategy(qcd_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_bins = np.array([1199., 1255, 1320, 1387, 1457, 1529, 1604, 1681, 1761, 1844, 1930, 2019, 2111, 2206, \n",
    "                        2305, 2406, 2512, 2620, 2733, 2849, 2969, 3093, 3221, 3353, 3490, 3632, 3778, 3928]).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(qr_run_n, params, sig_xsec=0):\n",
    "    qr_model_dir = '/eos/home-k/kiwoznia/data/QR_models/vae_run_'+str(params.vae_run_n)+'/qr_run_'+str(qr_run_n)\n",
    "    model_str = stco.make_qr_model_str(run_n_qr=qr_run_n, run_n_vae=params.vae_run_n, quantile=params.quantile, sig_id=params.sig_sample_id, sig_xsec=sig_xsec, strategy_id=params.strategy_id)\n",
    "    path = os.path.join(qr_model_dir, model_str)\n",
    "    model = tf.keras.models.load_model(path, custom_objects={'StdNormalization': layers.StdNormalization, 'QrModel': plmo.QrModel},compile=False)\n",
    "    print('loaded model ', model)\n",
    "    return model\n",
    "\n",
    "def compile_for_eval(model, accuracy_bins, params):\n",
    "    accuracy_bins = model.get_layer('Normalization')(accuracy_bins) # normalize inputs\n",
    "    ratio_metric = plmo.binned_quantile_dev_loss(params.quantile, accuracy_bins.numpy()) #None # quantile_dev_loss(params.quantile)\n",
    "    model.compile(loss=plmo.quantile_loss(params.quantile), ratio_metric=ratio_metric, optimizer=tf.keras.optimizers.Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wiggly = load(qr_run_n_wiggly, params)\n",
    "# compile manually because of custom loss & metrics\n",
    "model_wiggly = compile_for_eval(model_wiggly, accuracy_bins, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_smooth = load(qr_run_n_smooth, params)\n",
    "# compile manually because of custom loss & metrics\n",
    "model_smooth = compile_for_eval(model_smooth, accuracy_bins, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_discriminator_cut(discriminator, sample, score_strategy, feature_key='mJJ', plot_name='discr_cut', fig_dir=None, plot_suffix=''):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    x_min = np.min(sample[feature_key]) #norm_x.data_min_[0] #\n",
    "    x_max = np.max(sample[feature_key]) #norm_x.data_max_[0] #\n",
    "    an_score = score_strategy(sample)\n",
    "    plt.hist2d(sample[feature_key], an_score,\n",
    "           range=((x_min*0.9 , np.percentile(sample[feature_key], 1e2*(1-1e-5))), (np.min(an_score), np.percentile(an_score, 1e2*(1-1e-4)))), \n",
    "           norm=LogNorm(), bins=100)\n",
    "\n",
    "    xs = np.arange(x_min, x_max, 0.001*(x_max-x_min))\n",
    "    #import ipdb; ipdb.set_trace()\n",
    "    plt.plot(xs, discriminator.predict([xs,xs]) , '-', color='m', lw=2.5, label='selection cut')\n",
    "    plt.ylabel('L1 & L2 > LT')\n",
    "    plt.xlabel('$M_{jj}$ [GeV]')\n",
    "    plt.colorbar()\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_discriminator_cut(model_wiggly, qcd_test_sample, score_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_discriminator_cut(model_smooth, qcd_test_sample, score_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wiggly.evaluate(x_test,y_test,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_smooth.evaluate(x_test,y_test,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_szs = [16,32,64,128,256,512,1024,2048,4096]\n",
    "evals_wiggly = []\n",
    "evals_smooth = []\n",
    "for batch_sz in batch_szs:\n",
    "    evals_wiggly.append(model_wiggly.evaluate(x_test,y_test,batch_size=batch_sz))\n",
    "    evals_smooth.append(model_smooth.evaluate(x_test,y_test,batch_size=batch_sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(batch_szs,[w[2] for w in evals_wiggly],label='wiggly q dev')\n",
    "plt.plot(batch_szs,[s[2] for s in evals_smooth],label='smooth q dev')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('batch size')\n",
    "plt.ylabel('q dev')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(batch_szs,[w[1] for w in evals_wiggly],label='wiggly loss')\n",
    "plt.plot(batch_szs,[s[1] for s in evals_smooth],label='smooth loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('batch size')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate global deviation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_wiggly = model_wiggly.predict([x_test,y_test])\n",
    "y_pred_smooth = model_smooth.predict([x_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_dev_fun = plmo.quantile_dev_loss(params.quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_dev_fun(x_test,y_test,y_pred_wiggly).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate batching\n",
    "glob_metric_wiggly = []\n",
    "glob_metric_smooth = []\n",
    "for batch_sz in batch_szs:\n",
    "    metric_wiggly_per_b_sz = 0\n",
    "    metric_smooth_per_b_sz = 0\n",
    "    i = 0\n",
    "    while batch_sz*i < len(x_test):\n",
    "        # x_test inputs needed only for batch_sz evaluation -> no need to manually normalize\n",
    "        x_batch, y_batch = x_test[batch_sz*i:batch_sz*(i+1)], y_test[batch_sz*i:batch_sz*(i+1)]\n",
    "        metric_wiggly_per_b_sz += glob_dev_fun(x_batch, y_batch, y_pred_wiggly[batch_sz*i:batch_sz*(i+1)]).numpy()\n",
    "        metric_smooth_per_b_sz += glob_dev_fun(x_batch, y_batch, y_pred_smooth[batch_sz*i:batch_sz*(i+1)]).numpy()\n",
    "        i += 1\n",
    "    metric_wiggly_per_b_sz /= i\n",
    "    metric_smooth_per_b_sz /= i\n",
    "    glob_metric_wiggly.append(metric_wiggly_per_b_sz)\n",
    "    glob_metric_smooth.append(metric_smooth_per_b_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(batch_szs,glob_metric_wiggly,label='wiggly')\n",
    "plt.plot(batch_szs,glob_metric_smooth,label='smooth')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('batch size')\n",
    "plt.ylabel('global dev')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## second derivative metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scnd_deriv_metric():\n",
    "\n",
    "    def __init__(self, delta=1e-1, name='scndDerivLoss'):\n",
    "        self.name=name\n",
    "        self.delta = tf.constant(delta) # delta to approximate second derivative\n",
    "\n",
    "    # @tf.function\n",
    "    def __call__(self, model, inputs, targets, predictions): # for integration in regular TF -> compute predictions for delta-shifted inputs in outside train/test step\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        predictions = tf.squeeze(predictions)\n",
    "        pred_delta_right = tf.squeeze(model.predict([inputs+self.delta,targets])) # targets input not used in prediction\n",
    "        pred_delta_left = tf.squeeze(model.predict([inputs-self.delta,targets]))\n",
    "        \n",
    "        # 2nd finite diff\n",
    "        fini_diff2 = tf.math.divide_no_nan((pred_delta_right - 2*predictions + pred_delta_left),tf.math.square(self.delta))  \n",
    "\n",
    "        return tf.reduce_mean(tf.math.abs(fini_diff2)) # mean per batch (-> independent of batch-size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fini_diff2_fun = scnd_deriv_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fini_diff2_fun(model_wiggly,x_test,y_test,y_pred_wiggly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fini_diff2_fun(model_smooth,x_test,y_test,y_pred_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate batching\n",
    "deltas = [1e-1,5e-2,1e-2]\n",
    "glob_metric_wiggly = defaultdict(list)\n",
    "glob_metric_smooth = defaultdict(list)\n",
    "for delta in deltas:\n",
    "    fini_diff2_fun = scnd_deriv_metric(delta)\n",
    "    for batch_sz in batch_szs:\n",
    "        metric_wiggly_per_b_sz = 0\n",
    "        metric_smooth_per_b_sz = 0\n",
    "        i = 0\n",
    "        while batch_sz*i < len(x_test):\n",
    "            # x_test inputs needed only for batch_sz evaluation -> no need to manually normalize\n",
    "            x_batch, y_batch = x_test[batch_sz*i:batch_sz*(i+1)], y_test[batch_sz*i:batch_sz*(i+1)]\n",
    "            metric_wiggly_per_b_sz += fini_diff2_fun(model_wiggly, x_batch, y_batch, y_pred_wiggly[batch_sz*i:batch_sz*(i+1)]).numpy()\n",
    "            metric_smooth_per_b_sz += fini_diff2_fun(model_smooth, x_batch, y_batch, y_pred_smooth[batch_sz*i:batch_sz*(i+1)]).numpy()\n",
    "            i += 1\n",
    "        metric_wiggly_per_b_sz /= i\n",
    "        metric_smooth_per_b_sz /= i\n",
    "        glob_metric_wiggly[delta].append(metric_wiggly_per_b_sz)\n",
    "        glob_metric_smooth[delta].append(metric_smooth_per_b_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for delta in deltas:\n",
    "    plt.plot(batch_szs,glob_metric_wiggly[delta],label='wiggly ' + str(delta))\n",
    "    plt.plot(batch_szs,glob_metric_smooth[delta],label='smooth ' + str(delta))\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('batch size')\n",
    "plt.ylabel('2nd diff')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
